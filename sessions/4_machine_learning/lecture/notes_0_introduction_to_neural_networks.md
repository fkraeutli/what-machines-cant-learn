[Home](../../../README.md) / [Sessions](../../README.md) / [Session 4: Machine Learning](../README.md) / Introduction to Neural Networks

# Session 4: Machine Learning

* Introduction
* [Linear Functions](notes_1_linear_functions.md)
* [Modelling Data with Linear Functions](notes_2_modelling_data_with_linear_functions.md)
* [Representing Functions as Computational Graphs](notes_3_functions_as_computational_graphs.md)
* [Training a Computational Graph on Data](notes_4_training_a_computational_graph.md)
* [Neural Networks](notes_5_neural_networks.md)

## Introduction to Neural Networks

Through this session I would like students to develop an intuition on how Neural Networks work. For a thorough and, at the time of writing, current introduction to Deep Neural Networks I recommond the lectures on [Convolutional Neural Networks](https://www.youtube.com/watch?v=bNb2fEVKeEo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv) by [Fei-Fei Li](http://vision.stanford.edu/feifeili/), [Justin Johnson](http://cs.stanford.edu/people/jcjohns/) and [Serena Yeung](http://ai.stanford.edu/~syyeung/). 

Rather than employing the metaphor of the brain to explain their functioning I follow the approach also taken in the lectures above of by picturing them as what they are: computational graphs.

In this lecture I use a whiteboard to walk students from linear functions for representing and modelling data, to graph representations of functions and, finally, neural networks as a specific example of a computational graph.

Next: [Linear Functions](notes_1_linear_functions.md)
